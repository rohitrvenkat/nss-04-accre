{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set view options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spark session\n",
    "config = pyspark.SparkConf().setAll([('spark.executor.memory', '8g'),\n",
    "                                     ('spark.executor.cores', '3'),\n",
    "                                     ('spark.cores.max', '3'),\n",
    "                                     ('spark.driver.memory','8g'),\n",
    "                                     ('spark.driver.maxResultSize', '8g')])\n",
    "\n",
    "spark = SparkSession.builder.config(conf = config).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files as spark dataframes\n",
    "slurm_jobs = spark.read.option('header', True).csv('../data/fullsample.csv')\n",
    "\n",
    "ce5_log = (spark.read.option('delimiter', ' - ')\n",
    "           .csv('../data/slurm_wrapper_ce5.log')\n",
    "           .toDF('TIMESTAMP', 'USER', 'RETRY', 'RUNTIME', 'RETURNCODE', 'COMMAND')\n",
    ")\n",
    "\n",
    "ce6_log = (spark.read.option('delimiter', ' - ')\n",
    "           .csv('../data/slurm_wrapper_ce6.log')\n",
    "           .toDF('TIMESTAMP', 'USER', 'RETRY', 'RUNTIME', 'RETURNCODE', 'COMMAND')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up dataframes\n",
    "slurm_jobs = (slurm_jobs\n",
    "              .withColumn('STATE', F.regexp_replace('STATE', r'CANCELLED by.*', 'CANCELLED by USER'))\n",
    "              .withColumn('BEGIN', F.to_timestamp(F.col('BEGIN')))\n",
    "              .withColumn('END', F.to_timestamp(F.col('END')))\n",
    "              .withColumn('NODES', F.col('NODES').cast('int'))\n",
    "              .withColumn('CPUS', F.col('CPUS').cast('int'))\n",
    "              .withColumn('SIGNAL', F.regexp_extract(F.col('EXITCODE'), '.*:(\\d+)', 1).cast('int'))\n",
    "              .withColumn('EXITCODE', F.regexp_extract(F.col('EXITCODE'), '(\\d+):.*', 1).cast('int'))\n",
    "              .withColumn('REQMEMxNODE', F.regexp_replace('REQMEM', 'Mn', '').cast('long') * F.col('NODES'))\n",
    "              .withColumn('REQMEMxCPU', F.regexp_replace('REQMEM', 'Mc', '').cast('long') * F.col('CPUS'))\n",
    "              .withColumn('REQMEMTOT', F.coalesce(F.col('REQMEMxNODE'), F.col('REQMEMxCPU')))\n",
    "              .withColumn('REQMEMPERCORE', F.col('REQMEMTOT') / F.col('CPUS'))\n",
    "              .withColumn('USEDMEM', F.regexp_replace('USEDMEM', 'M', '').cast('long'))\n",
    "              .drop('REQMEMxNODE', 'REQMEMxCPU')\n",
    "              .filter('END is not null')\n",
    ")\n",
    "\n",
    "ce5_log = (ce5_log\n",
    "           .withColumn('TIMESTAMP', F.to_timestamp(F.col('TIMESTAMP')))\n",
    "           .withColumn('USER', F.regexp_replace('USER', 'user ', '').cast('int'))\n",
    "           .withColumn('RETRY', F.regexp_replace('RETRY', 'retry ', '').cast('int'))\n",
    "           .withColumn('RUNTIME', F.regexp_replace('RUNTIME', 'time ', '').cast('float'))\n",
    "           .withColumn('RETURNCODE', F.regexp_replace('RETURNCODE', 'returncode ', '').cast('int'))\n",
    "           .withColumn('COMMAND', F.regexp_extract(F.col('COMMAND'), '.*/usr/bin/(\\w+)', 1))\n",
    ")\n",
    "\n",
    "ce6_log = (ce6_log\n",
    "           .withColumn('TIMESTAMP', F.to_timestamp(F.col('TIMESTAMP')))\n",
    "           .withColumn('USER', F.regexp_replace('USER', 'user ', '').cast('int'))\n",
    "           .withColumn('RETRY', F.regexp_replace('RETRY', 'retry ', '').cast('int'))\n",
    "           .withColumn('RUNTIME', F.regexp_replace('RUNTIME', 'time ', '').cast('float'))\n",
    "           .withColumn('RETURNCODE', F.regexp_replace('RETURNCODE', 'returncode ', '').cast('int'))\n",
    "           .withColumn('COMMAND', F.regexp_extract(F.col('COMMAND'), '.*/usr/bin/(\\w+)', 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate started jobs by minute\n",
    "started_jobs = (slurm_jobs\n",
    "                .groupBy(F.date_trunc('minute', F.col('BEGIN')).alias('TIMESTAMP'))\n",
    "                .agg(F.count(F.col('BEGIN')).alias('STARTEDJOBS'))\n",
    "                .sort('TIMESTAMP')\n",
    "                .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "started_jobs = started_jobs.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate ended jobs by minute\n",
    "ended_jobs = (slurm_jobs\n",
    "              .groupBy(F.date_trunc('minute', F.col('END')).alias('TIMESTAMP'))\n",
    "              .agg(F.count(F.col('END')).alias('ENDEDJOBS'))\n",
    "              .sort('TIMESTAMP')\n",
    "              .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ended_jobs = ended_jobs.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate running jobs by minute\n",
    "slurm_jobs_started = slurm_jobs.select('BEGIN').withColumnRenamed('BEGIN', 'TIMESTAMP').withColumn('RUNNINGJOBS', F.lit(1))\n",
    "slurm_jobs_ended = slurm_jobs.select('END').withColumnRenamed('END', 'TIMESTAMP').withColumn('RUNNINGJOBS', F.lit(-1))\n",
    "\n",
    "running_jobs = (slurm_jobs_started\n",
    "                .union(slurm_jobs_ended)\n",
    "                .sort('TIMESTAMP')\n",
    "                .withColumn('RUNNINGJOBS', F.sum(F.col('RUNNINGJOBS')).over(Window.orderBy('TIMESTAMP')))\n",
    "                .select('TIMESTAMP', 'RUNNINGJOBS')\n",
    "                .dropDuplicates()\n",
    "                .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "running_jobs = running_jobs.set_index('TIMESTAMP').reindex(idx, method = 'pad', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate requested memory by minute\n",
    "slurm_jobs_started = slurm_jobs.select('BEGIN', 'REQMEMTOT').withColumnRenamed('BEGIN', 'TIMESTAMP').withColumn('REQMEMTOT', F.col('REQMEMTOT'))\n",
    "slurm_jobs_ended = slurm_jobs.select('END', 'REQMEMTOT').withColumnRenamed('END', 'TIMESTAMP').withColumn('REQMEMTOT', F.col('REQMEMTOT') * -1)\n",
    "\n",
    "requested_memory = (slurm_jobs_started\n",
    "                    .union(slurm_jobs_ended)\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .withColumn('REQMEMTOT', F.sum(F.col('REQMEMTOT')).over(Window.orderBy('TIMESTAMP')))\n",
    "                    .select('TIMESTAMP', 'REQMEMTOT')\n",
    "                    .dropDuplicates()\n",
    "                    .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "requested_memory = requested_memory.set_index('TIMESTAMP').reindex(idx, method = 'pad', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate used memory by minute\n",
    "slurm_jobs_started = slurm_jobs.select('BEGIN', 'USEDMEM').withColumnRenamed('BEGIN', 'TIMESTAMP').withColumn('USEDMEM', F.col('USEDMEM'))\n",
    "slurm_jobs_ended = slurm_jobs.select('END', 'USEDMEM').withColumnRenamed('END', 'TIMESTAMP').withColumn('USEDMEM', F.col('USEDMEM') * -1)\n",
    "\n",
    "used_memory = (slurm_jobs_started\n",
    "               .union(slurm_jobs_ended)\n",
    "               .sort('TIMESTAMP')\n",
    "               .withColumn('USEDMEM', F.sum(F.col('USEDMEM')).over(Window.orderBy('TIMESTAMP')))\n",
    "               .select('TIMESTAMP', 'USEDMEM')\n",
    "               .dropDuplicates()\n",
    "               .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "used_memory = used_memory.set_index('TIMESTAMP').reindex(idx, method = 'pad', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate used nodes by minute (gross overestimate since jobs can share nodes)\n",
    "slurm_jobs_started = slurm_jobs.select('BEGIN', 'NODES').withColumnRenamed('BEGIN', 'TIMESTAMP').withColumn('NODES', F.col('NODES'))\n",
    "slurm_jobs_ended = slurm_jobs.select('END', 'NODES').withColumnRenamed('END', 'TIMESTAMP').withColumn('NODES', F.col('NODES') * -1)\n",
    "\n",
    "used_nodes = (slurm_jobs_started\n",
    "              .union(slurm_jobs_ended)\n",
    "              .sort('TIMESTAMP')\n",
    "              .withColumn('NODES', F.sum(F.col('NODES')).over(Window.orderBy('TIMESTAMP')))\n",
    "              .select('TIMESTAMP', 'NODES')\n",
    "              .dropDuplicates()\n",
    "              .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "used_nodes = used_nodes.set_index('TIMESTAMP').reindex(idx, method = 'pad', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate used cpus by minute\n",
    "slurm_jobs_started = slurm_jobs.select('BEGIN', 'CPUS').withColumnRenamed('BEGIN', 'TIMESTAMP').withColumn('CPUS', F.col('CPUS'))\n",
    "slurm_jobs_ended = slurm_jobs.select('END', 'CPUS').withColumnRenamed('END', 'TIMESTAMP').withColumn('CPUS', F.col('CPUS') * -1)\n",
    "\n",
    "used_cpus = (slurm_jobs_started\n",
    "             .union(slurm_jobs_ended)\n",
    "             .sort('TIMESTAMP')\n",
    "             .withColumn('CPUS', F.sum(F.col('CPUS')).over(Window.orderBy('TIMESTAMP')))\n",
    "             .select('TIMESTAMP', 'CPUS')\n",
    "             .dropDuplicates()\n",
    "             .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "used_cpus = used_cpus.set_index('TIMESTAMP').reindex(idx, method = 'pad', fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all commands by minute\n",
    "ce5_all_commands = (ce5_log\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.count(F.col('TIMESTAMP')).alias('COMMANDS'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_all_commands = (ce6_log\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.count(F.col('TIMESTAMP')).alias('COMMANDS'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_all_commands = ce5_all_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_all_commands = ce6_all_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sbatch commands by minute\n",
    "ce5_sbatch_commands = (ce5_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.count(F.col('TIMESTAMP')).alias('SBATCH_COMMANDS'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_sbatch_commands = (ce6_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.count(F.col('TIMESTAMP')).alias('SBATCH_COMMANDS'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_sbatch_commands = ce5_sbatch_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_sbatch_commands = ce6_sbatch_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate scontrol commands by minute\n",
    "ce5_scontrol_commands = (ce5_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.count(F.col('TIMESTAMP')).alias('SCONTROL_COMMANDS'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_scontrol_commands = (ce6_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.count(F.col('TIMESTAMP')).alias('SCONTROL_COMMANDS'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_scontrol_commands = ce5_scontrol_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_scontrol_commands = ce6_scontrol_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate user 9204 sbatch commands by minute\n",
    "ce5_user_9204_sbatch_commands = (ce5_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"')\n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.count(F.col('TIMESTAMP')).alias('USER_9204_SBATCH_COMMANDS'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_user_9204_sbatch_commands = (ce6_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"')\n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.count(F.col('TIMESTAMP')).alias('USER_9204_SBATCH_COMMANDS'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_user_9204_sbatch_commands = ce5_user_9204_sbatch_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_user_9204_sbatch_commands = ce6_user_9204_sbatch_commands.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all timeouts by minute\n",
    "ce5_all_timeouts = (ce5_log\n",
    "                    .filter('RUNTIME > 15') \n",
    "                    .filter('RETURNCODE > 0')\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.count(F.col('TIMESTAMP')).alias('TIMEOUTS'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_all_timeouts = (ce6_log\n",
    "                    .filter('RUNTIME > 15') \n",
    "                    .filter('RETURNCODE > 0')\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.count(F.col('TIMESTAMP')).alias('TIMEOUTS'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_all_timeouts = ce5_all_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_all_timeouts = ce6_all_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sbatch timeouts by minute\n",
    "ce5_sbatch_timeouts = (ce5_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .filter('RUNTIME > 15') \n",
    "                       .filter('RETURNCODE > 0')\n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.count(F.col('TIMESTAMP')).alias('SBATCH_TIMEOUTS'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_sbatch_timeouts = (ce6_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .filter('RUNTIME > 15') \n",
    "                       .filter('RETURNCODE > 0')\n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.count(F.col('TIMESTAMP')).alias('SBATCH_TIMEOUTS'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_sbatch_timeouts = ce5_sbatch_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_sbatch_timeouts = ce6_sbatch_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate scontrol timeouts by minute\n",
    "ce5_scontrol_timeouts = (ce5_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .filter('RUNTIME > 15') \n",
    "                         .filter('RETURNCODE > 0') \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.count(F.col('TIMESTAMP')).alias('SCONTROL_TIMEOUTS'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_scontrol_timeouts = (ce6_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .filter('RUNTIME > 15') \n",
    "                         .filter('RETURNCODE > 0')                         \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.count(F.col('TIMESTAMP')).alias('SCONTROL_TIMEOUTS'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()  \n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_scontrol_timeouts = ce5_scontrol_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_scontrol_timeouts = ce6_scontrol_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate user 9204 sbatch timeouts by minute\n",
    "ce5_user_9204_sbatch_timeouts = (ce5_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"')\n",
    "                                 .filter('RUNTIME > 15') \n",
    "                                 .filter('RETURNCODE > 0')\n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.count(F.col('TIMESTAMP')).alias('USER_9204_SBATCH_TIMEOUTS'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_user_9204_sbatch_timeouts = (ce6_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"') \n",
    "                                 .filter('RUNTIME > 15') \n",
    "                                 .filter('RETURNCODE > 0')\n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.count(F.col('TIMESTAMP')).alias('USER_9204_SBATCH_TIMEOUTS'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_user_9204_sbatch_timeouts = ce5_user_9204_sbatch_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_user_9204_sbatch_timeouts = ce6_user_9204_sbatch_timeouts.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all runtimes by minute\n",
    "ce5_all_runtimes = (ce5_log\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.sum(F.col('RUNTIME')).alias('RUNTIMES'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_all_runtimes = (ce6_log\n",
    "                    .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                    .agg(F.sum(F.col('RUNTIME')).alias('RUNTIMES'))\n",
    "                    .sort('TIMESTAMP')\n",
    "                    .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_all_runtimes = ce5_all_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_all_runtimes = ce6_all_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sbatch runtimes by minute\n",
    "ce5_sbatch_runtimes = (ce5_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.sum(F.col('RUNTIME')).alias('SBATCH_RUNTIMES'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_sbatch_runtimes = (ce6_log\n",
    "                       .filter('COMMAND = \"sbatch\"') \n",
    "                       .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                       .agg(F.sum(F.col('RUNTIME')).alias('SBATCH_RUNTIMES'))\n",
    "                       .sort('TIMESTAMP')\n",
    "                       .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_sbatch_runtimes = ce5_sbatch_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_sbatch_runtimes = ce6_sbatch_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate scontrol runtimes by minute\n",
    "ce5_scontrol_runtimes = (ce5_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.sum(F.col('RUNTIME')).alias('SCONTROL_RUNTIMES'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_scontrol_runtimes = (ce6_log\n",
    "                         .filter('COMMAND = \"scontrol\"') \n",
    "                         .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                         .agg(F.sum(F.col('RUNTIME')).alias('SCONTROL_RUNTIMES'))\n",
    "                         .sort('TIMESTAMP')\n",
    "                         .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_scontrol_runtimes = ce5_scontrol_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_scontrol_runtimes = ce6_scontrol_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate user 9204 sbatch runtimes by minute\n",
    "ce5_user_9204_sbatch_runtimes = (ce5_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"') \n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.sum(F.col('RUNTIME')).alias('USER_9204_SBATCH_RUNTIMES'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()  \n",
    ")\n",
    "\n",
    "ce6_user_9204_sbatch_runtimes = (ce6_log\n",
    "                                 .filter('USER = 9204') \n",
    "                                 .filter('COMMAND = \"sbatch\"') \n",
    "                                 .groupBy(F.date_trunc('minute', F.col('TIMESTAMP')).alias('TIMESTAMP'))\n",
    "                                 .agg(F.sum(F.col('RUNTIME')).alias('USER_9204_SBATCH_RUNTIMES'))\n",
    "                                 .sort('TIMESTAMP')\n",
    "                                 .toPandas()\n",
    ")\n",
    "\n",
    "idx = pd.date_range('2020-10-01', '2021-10-08', freq = '1min', name = 'TIMESTAMP')\n",
    "ce5_user_9204_sbatch_runtimes = ce5_user_9204_sbatch_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)\n",
    "ce6_user_9204_sbatch_runtimes = ce6_user_9204_sbatch_runtimes.set_index('TIMESTAMP').reindex(idx, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge slurm time series data together and write to csv\n",
    "slurm_dfs = [started_jobs, ended_jobs, running_jobs, requested_memory, used_memory, used_nodes, used_cpus]\n",
    "\n",
    "slurm = reduce(lambda left,right: pd.merge(left, right, left_index = True, right_index = True), slurm_dfs)\n",
    "slurm.to_csv('../data/slurm_time_series.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ce5 time series data together and write to csv\n",
    "ce5_dfs = [ce5_all_commands, ce5_sbatch_commands, ce5_scontrol_commands, ce5_user_9204_sbatch_commands,\n",
    "           ce5_all_timeouts, ce5_sbatch_timeouts, ce5_scontrol_timeouts, ce5_user_9204_sbatch_timeouts,\n",
    "           ce5_all_runtimes, ce5_sbatch_runtimes, ce5_scontrol_runtimes, ce5_user_9204_sbatch_runtimes]\n",
    "\n",
    "ce5 = reduce(lambda left,right: pd.merge(left, right, left_index = True, right_index = True), ce5_dfs)\n",
    "ce5.to_csv('../data/ce5_time_series.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ce6 time series data together and write to csv\n",
    "ce6_dfs = [ce6_all_commands, ce6_sbatch_commands, ce6_scontrol_commands, ce6_user_9204_sbatch_commands,\n",
    "           ce6_all_timeouts, ce6_sbatch_timeouts, ce6_scontrol_timeouts, ce6_user_9204_sbatch_timeouts,\n",
    "           ce6_all_runtimes, ce6_sbatch_runtimes, ce6_scontrol_runtimes, ce6_user_9204_sbatch_runtimes]\n",
    "\n",
    "ce6 = reduce(lambda left,right: pd.merge(left, right, left_index = True, right_index = True), ce6_dfs)\n",
    "ce6.to_csv('../data/ce6_time_series.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ce5 and ce6 time series data together and write to csv\n",
    "ce5_ce6 = ce5 + ce6\n",
    "ce5_ce6.to_csv('../data/ce5_ce6_time_series.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge slurm, ce5, and ce6 time series data together and write to csv\n",
    "dfs = [slurm, ce5_ce6, ce5.add_prefix('CE5_'), ce6.add_prefix('CE6_')]\n",
    "\n",
    "slurm_ce5_ce6 = reduce(lambda left,right: pd.merge(left, right, left_index = True, right_index = True), dfs)\n",
    "slurm_ce5_ce6.to_csv('../data/slurm_ce5_ce6_time_series.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ce5 and ce6 log files, sort, and write to csv\n",
    "ce5_ce6_log = (ce5_log\n",
    "               .union(ce6_log)\n",
    "               .sort('TIMESTAMP', 'RUNTIME')\n",
    "               .toPandas()\n",
    ")\n",
    "\n",
    "ce5_ce6_log.to_csv('../data/slurm_wrapper_ce5_ce6.log', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d6140ef0c675026b0200147df87972487ebc0097827c4c765c9e0dcd9cf7b2f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
